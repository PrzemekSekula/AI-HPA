{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorforce\n",
    "\n",
    "from tensorforce.agents import Agent\n",
    "from tensorforce.environments import Environment\n",
    "import tensorflow as tf\n",
    "from helper import *\n",
    "\n",
    "from datetime import datetime\n",
    "from time import sleep, time\n",
    "from collections import deque\n",
    "\n",
    "# Prometheus\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "\n",
    "from metric import Metric\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "print ('TF Version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnvironment(Environment):\n",
    "\n",
    "    def __init__(self, nr_stored_states = 10, max_pods = 5, \n",
    "                 reward_function = None, deployments = None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            nr_stored_states - number of states to be returned\n",
    "            max_pods         - maximum number of pods (for actions)\n",
    "            reward_function  - function that returns the reward. Should have one argument \n",
    "                               (dataframe)\n",
    "            deployments      - list of deployment names. If none, all the deployments from \n",
    "                               metric agent are used\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nr_stored_states = nr_stored_states # How many last states should be stored\n",
    "        self.max_pods = max_pods\n",
    "        \n",
    "        \n",
    "        # Prometheus connection handle\n",
    "        self.prom = PrometheusConnect(url =\"http://127.0.0.1:8001/\", disable_ssl=True)\n",
    "        \n",
    "        if reward_function is None:\n",
    "            self.reward_function = self._reward_default\n",
    "        else:\n",
    "            self.reward_function = reward_function\n",
    "\n",
    "        self.metrics = deque(maxlen=nr_stored_states)\n",
    "        \n",
    "        \n",
    "        # Stop environment\n",
    "        self.envDone = 0\n",
    "        self.current_step = 0\n",
    "    \n",
    "        ### Used for rewards\n",
    "        self.nrDone = 0\n",
    "        self.nrDead = 0\n",
    "        self.nrErr5xx = 0\n",
    "        \n",
    "        if deployments is None:\n",
    "            self.deployments = list(self.metrics2df().controlled_deployment.unique())\n",
    "        else:\n",
    "            self.deployments = deployments\n",
    "\n",
    "            \n",
    "            \n",
    "        m = Metric(deployments = self.deployments, prom = self.prom)\n",
    "        self.metrics.extend([m] * nr_stored_states)\n",
    "            \n",
    "            \n",
    "        ## For debuging\n",
    "        self.action_list = []\n",
    "        self.number_resets = 0\n",
    "    \n",
    "    def states(self):\n",
    "        return dict(\n",
    "            type='float', \n",
    "            shape=(len(self.getState()), self.nr_stored_states)\n",
    "        )\n",
    "        \n",
    "    def actions(self):\n",
    "        return dict(\n",
    "            type='float', \n",
    "            shape=(len(self.deployments), ),\n",
    "            min_value = 1.0,\n",
    "            max_value = self.max_pods\n",
    "        )\n",
    "\n",
    "    # Optional: should only be defined if environment has a natural fixed\n",
    "    # maximum episode length; otherwise specify maximum number of training\n",
    "    # timesteps via Environment.create(..., max_episode_timesteps=???)\n",
    "    def max_episode_timesteps(self):\n",
    "        return super().max_episode_timesteps()\n",
    "\n",
    "    # Optional additional steps to close environment\n",
    "    def close(self):\n",
    "        super().close()\n",
    "\n",
    "    def reset(self):\n",
    "        # Stop environment\n",
    "        self.number_resets += 1\n",
    "        \n",
    "        self.envDone = 0\n",
    "        self.current_step = 0\n",
    "    \n",
    "        ### Used for rewards\n",
    "        self.nrDone = 0\n",
    "        self.nrDead = 0\n",
    "        self.nrErr5xx = 0\n",
    "                \n",
    "        self.action_list = []\n",
    "                \n",
    "        return self.getState()\n",
    "\n",
    "    \n",
    "    def getState(self):\n",
    "        self.metrics.append(Metric(deployments = self.deployments, prom = self.prom))\n",
    "        obs = self.metrics[-1].metricDF.value.to_numpy()\n",
    "        if len(obs.shape) == 1:\n",
    "            obs = obs[:, np.newaxis]\n",
    "        return obs\n",
    "    \n",
    "    \n",
    "    def execute(self, actions):\n",
    "        self.action_list.append(actions)\n",
    "        #print (actions)\n",
    "        \n",
    "        actions = np.round(actions)\n",
    "        actions = actions.astype(int)\n",
    "        \n",
    "        for deployment, action in zip(self.deployments, actions):\n",
    "            action = str(int(100*np.round(action)))\n",
    "            #print (deployment, action)\n",
    "            subprocess.run(\n",
    "                ['sh', './shellscripts/set_pods.sh', deployment, action], \n",
    "                text=True, capture_output = True)\n",
    "            \n",
    "        self.current_step += 1\n",
    "     \n",
    "        \n",
    "        next_state = self.getState()\n",
    "        terminal = False  # Always False if no \"natural\" terminal state\n",
    "        reward = self.reward()\n",
    "        return next_state, terminal, reward\n",
    "             \n",
    "    def _reward_default(self, df):\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    def reward(self):\n",
    "        return self.reward_function(self.metrics2df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment.create(\n",
    "    environment=CustomEnvironment(\n",
    "        max_pods = 5,\n",
    "        deployments = ['carts', 'catalogue', 'front-end', 'orders', 'payment', 'shipping', 'user',]\n",
    "    ), \n",
    "    max_episode_timesteps=100,\n",
    ")\n",
    "print (environment.getState().shape)\n",
    "print (environment.deployments, len(environment.deployments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = environment.metrics[-1].metricDF\n",
    "df[(df.resource == 'pod') & (df.deployment.isin(environment.deployments))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = environment.metrics2df().sort_values('controlled_deployment')\n",
    "df = df[(df.resource == 'pod') & (df.controlled_deployment.isin(environment.deployments))]\n",
    "dfres = pd.DataFrame(columns = list(df.controlled_deployment))\n",
    "dfres.loc[datetime.now(), :] = list(df.value)\n",
    "environment.execute([4, 5, 4, 5, 4, 5, 4] * 7);\n",
    "for i in range(30):\n",
    "    print (f'Iteration {i}/30, datetime: {datetime.now()}        \\r', end='')\n",
    "    df = environment.metrics2df().sort_values('controlled_deployment')\n",
    "    df = df[(df.resource == 'pod') & (df.controlled_deployment.isin(environment.deployments))]\n",
    "    dfres.loc[datetime.now(), :] = list(df.value)\n",
    "    sleep(1)\n",
    "dfres_up = dfres.copy()\n",
    "dfres_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres_up.iloc[0:20].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = environment.metrics2df().sort_values('controlled_deployment')\n",
    "df = df[(df.resource == 'pod') & (df.controlled_deployment.isin(environment.deployments))]\n",
    "dfres = pd.DataFrame(columns = list(df.controlled_deployment))\n",
    "dfres.loc[datetime.now(), :] = list(df.value)\n",
    "environment.execute([1] * 7 );\n",
    "for i in range(200):\n",
    "    print (f'Iteration {i}/200, datetime: {datetime.now()}        \\r', end='')\n",
    "    df = environment.metrics2df().sort_values('controlled_deployment')\n",
    "    df = df[(df.resource == 'pod') & (df.controlled_deployment.isin(environment.deployments))]\n",
    "    dfres.loc[datetime.now(), :] = list(df.value)\n",
    "    sleep(1)\n",
    "dfres_down = dfres.copy()    \n",
    "dfres_down.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres_down = dfres.copy() \n",
    "dfres_down.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_RUNNER = False\n",
    "if USE_RUNNER:\n",
    "    agent = Agent.create(agent='random', environment=environment)   \n",
    "    runner = tensorforce.execution.Runner(\n",
    "        agent=agent,\n",
    "        environment=environment,\n",
    "        max_episode_timesteps=100\n",
    "    )\n",
    "    runner.run(num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.create(agent='random', environment=environment)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = environment.metrics2df().sort_values('controlled_deployment')\n",
    "df = df[(df.resource == 'pod') & (df.controlled_deployment.isin(environment.deployments))]\n",
    "df_pods = pd.DataFrame(columns = list(df.controlled_deployment))\n",
    "df_actions = df_pods.copy()\n",
    "\n",
    "for episode_nr in range(5):\n",
    "    episode_states = list()\n",
    "    episode_internals = list()\n",
    "    episode_actions = list()\n",
    "    episode_terminal = list()\n",
    "    episode_reward = list()\n",
    "\n",
    "    states = environment.reset()\n",
    "    internals = agent.initial_internals()\n",
    "    terminal = False\n",
    "    while not terminal:\n",
    "        episode_states.append(states)\n",
    "        episode_internals.append(internals)\n",
    "        actions, internals = agent.act(\n",
    "            states=states, internals=internals, independent=True, deterministic=False\n",
    "        )\n",
    "        episode_actions.append(actions)\n",
    "        states, terminal, reward = environment.execute(actions=actions)\n",
    "        episode_terminal.append(terminal)\n",
    "        episode_reward.append(reward)\n",
    "        terminal = True\n",
    "        \n",
    "    if False: # No experience/update for random agent    \n",
    "        agent.experience(\n",
    "            states=episode_states, internals=episode_internals,\n",
    "            actions=episode_actions, terminal=episode_terminal,\n",
    "            reward=episode_reward\n",
    "        )\n",
    "    \n",
    "        agent.update()\n",
    "\n",
    "    df = environment.metrics2df().sort_values('controlled_deployment')\n",
    "    df = df[(df.resource == 'pod') & (df.controlled_deployment.isin(environment.deployments))]\n",
    "    \n",
    "    t = datetime.now()\n",
    "    df_pods.loc[t, :] = list(df.value)\n",
    "    df_actions.loc[t, :] = list(actions)    \n",
    "    \n",
    "    for i in range(10):\n",
    "        sleep(3)\n",
    "        print (f'Episode {episode_nr} ({i+1}/10).         \\r', end='')\n",
    "        df = environment.metrics2df().sort_values('controlled_deployment')\n",
    "        df = df[(df.resource == 'pod') & (df.controlled_deployment.isin(environment.deployments))]\n",
    "        t = datetime.now()\n",
    "        df_pods.loc[t, :] = list(df.value)\n",
    "    df_actions.loc[t, :] = list(actions)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions.plot()\n",
    "df_pods.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
