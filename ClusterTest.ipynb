{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster tests\n",
    "- This notebook serves a purpose of testing if the cluster simulation works.\n",
    "- It is divided on four subsections:\n",
    "    - section 1: helper code (contains various helper functions)\n",
    "    - section 2: Static cluster - contains an experiment conducted on a static cluster\n",
    "    - section 3: Basic HPA - cluster is being scaled with a basic HPA (we do not pay attention into maximum CPU usage\n",
    "    - section 4: CPU-sensitive HPA - this time cluster is being scaled with a big smarter scaler, that pays attention into CPU usage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time, sleep\n",
    "\n",
    "from cluster_simulator import SimpleCluster, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dic2DF(dic):\n",
    "    \"\"\"\n",
    "    Changes a dictionary with metrics into Pandas dataframe \n",
    "    \"\"\"\n",
    "    \n",
    "    def unravel_column(df, colname):\n",
    "        \"\"\"\n",
    "        A helper function that unravels a list of metrics into separate DF columns\n",
    "        \"\"\"\n",
    "        df2 = pd.DataFrame(df[colname].tolist(), index= df.index)\n",
    "        cols = ['pods', 'activePods', 'activeTasks', 'cpu', 'cpu_max', 'memory', 'memory_max', 'queueTasks', 'nrDone', 'nrDead', 'nrErr5xx']\n",
    "        cols = [f'{colname}_{x}' for x in cols]\n",
    "        df2.columns = cols\n",
    "        df = pd.concat([df, df2], axis=1).drop(colname, axis=1)\n",
    "        return df\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(dic, orient='index')\n",
    "    df.columns = ['totalTasks', 'totalDone', 'dep1', 'dep2', 'dep3']\n",
    "    for i in range(1, 4):\n",
    "        df = unravel_column(df, f'dep{i}')\n",
    "    return df\n",
    "\n",
    "\n",
    "def plotDeploymentData(df, sufix = 'pods', legend = None):\n",
    "    \"\"\"\n",
    "    Plots a selected metric for each deployment separately \n",
    "    Arguments:\n",
    "        df     - dataframe prepared by dic2DF function\n",
    "        sufix  - name of the metric (corresponds to column names \n",
    "                 from df)\n",
    "        legend - legend to be displayed. If None, a standard\n",
    "                 legend is displayed\n",
    "    \"\"\"\n",
    "    cols = [x for x in df.columns if x[-len(sufix):] == sufix]\n",
    "    df[cols].plot()\n",
    "    plt.title(sufix)\n",
    "    if legend is not None:\n",
    "        plt.legend(legend)\n",
    "    plt.xlabel('milicroseconds')\n",
    "\n",
    "def plotDeploymentDataSum(df, sufix = 'pods'):\n",
    "    \"\"\"\n",
    "    Summarises a selected metric over a deployment and plots it \n",
    "    Arguments:\n",
    "        df     - dataframe prepared by dic2DF function\n",
    "        sufix  - name of the metric (corresponds to column names \n",
    "                 from df)\n",
    "    \"\"\"    \n",
    "    cols = [x for x in df.columns if x[-len(sufix):] == sufix]\n",
    "    tmp = df[cols].copy()\n",
    "    tmp[sufix] = tmp[cols].sum(axis=1)\n",
    "    tmp[[sufix]].plot()\n",
    "    plt.title(f'{sufix} (total)')\n",
    "    plt.legend('')\n",
    "    plt.xlabel('miliseconds')\n",
    "\n",
    "\n",
    "def plotTasks(df):\n",
    "    sufix = 'nrDone'\n",
    "    cols = [x for x in df.columns if x[-len(sufix):] == sufix]\n",
    "    tmp = df[[cols[-1]]].copy()\n",
    "    #tmp[sufix] = tmp[cols].sum(axis=1)\n",
    "    tmp['received'] = df['totalTasks']\n",
    "    tmp = tmp[['received', cols[-1]]]\n",
    "    tmp.columns = ['received', 'finished']\n",
    "    tmp.plot()    \n",
    "    plt.title('Number of tasks')\n",
    "    plt.xlabel('miliseconds')\n",
    "    \n",
    "def plotClusterHistory(df):\n",
    "    plotDeploymentData(df)\n",
    "    plotDeploymentData(df, 'activePods', legend='')\n",
    "    plotDeploymentData(df, 'activeTasks', legend='')\n",
    "    plotDeploymentData(df, 'queueTasks', legend='')\n",
    "    plotDeploymentDataSum(df, 'cpu')\n",
    "    plotDeploymentData(df, 'cpu', legend='')\n",
    "    plotDeploymentData(df, 'nrDone', legend='')\n",
    "    plotDeploymentData(df, 'nrErr5xx', legend='')\n",
    "    plotTasks(df)\n",
    "    \n",
    "    \n",
    "def computeCost(df):\n",
    "    tmp = df[df.totalDone < df.totalTasks.max()]\n",
    "    working_cost = (tmp.dep1_pods + tmp.dep2_pods + tmp.dep3_pods).sum()\n",
    "    total_cost = (df.dep1_pods + df.dep2_pods + df.dep3_pods).sum()\n",
    "    return working_cost, total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCluster():\n",
    "    \"\"\" Returns a cluster used in this notebook (all experiments)\"\"\"\n",
    "    return SimpleCluster(\n",
    "        durations = [1e3, 6e3, 2e3], \n",
    "        pods = [1, 4, 2])\n",
    "\n",
    "\n",
    "TASKS = [4, 6, 2, 4, ] + [0 ]* 7 + [7, 12, 10, 21] + [0] * 3 + [11, 8, 13, 7] * 3\n",
    "NR_STEPS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster description\n",
    "The cluster here is built of three deployments: Dep1, Dep2 and Dep3.\n",
    "The tasks flow in series, from Dep1, to Dep3. The deployment descriptions are as follows:\n",
    "- Deployment 1:\n",
    "    - Number of pods: 1\n",
    "    - Duration (how long the task is being processed): 1ms += 30%, (random.normal)\n",
    "    - CPU consumption: 20 units per working pod +-30%, (random.normal), (+ 1 unit per pod even if it is not working\n",
    "    - Memory consumption: 20 units per working pod +-30%, (random.normal), (+ 1 unit per pod even if it is not working\n",
    "- Deployment 2:\n",
    "    - Number of pods: 4\n",
    "    - Duration (how long the task is being processed): 6ms += 30%, (random.normal)\n",
    "    - CPU consumption: 20 units per working pod +-30%, (random.normal), (+ 1 unit per pod even if it is not working\n",
    "    - Memory consumption: 20 units per working pod +-30%, (random.normal), (+ 1 unit per pod even if it is not working\n",
    "- Deployment 3:\n",
    "    - Number of pods: 2\n",
    "    - Duration (how long the task is being processed): 2ms += 30%, (random.normal)\n",
    "    - CPU consumption: 20 units per working pod +-30%, (random.normal), (+ 1 unit per pod even if it is not working\n",
    "    - Memory consumption: 20 units per working pod +-30%, (random.normal), (+ 1 unit per pod even if it is not working\n",
    "\n",
    "\n",
    "\n",
    "![Alt text](./images/ClusterScheme.jpg \"Cluster Scheme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Static cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can observe a cluster that does not change in time. The cluster is fed with tasks (requests) defined in `TASKS` variable (each value corresponds to the number of tasks / iteration). The tasks are pushed through the cluster from the first to the last deployment. \n",
    "\n",
    "The results are presented in the charts, with the meaning as follows:\n",
    "- `pods` - total number of the active pods. This cluster is not scaled, so the values are static (1 pod for dep1, 4 pods for dep2 and 2 pods for dep3)\n",
    "- `activePods` - the number of pods that are active (are working on a task)\n",
    "- `queueTasks` - the number of tasks that are already sent to the deployment but cannot be run due to the lack of free pods (tasks in the queue)\n",
    "- `cpu (total)` - total cluster cpu usage\n",
    "- `cpu` - cpu usage per deployment\n",
    "- `Number of tasks` - Total number of the tasks received and finished by the cluster. This is a counter\n",
    "- `nrDone` - total number of finished tasks (by deployment). This is a counter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = createCluster()\n",
    "res = {}\n",
    "res[0] = cluster.getMetrics()\n",
    "#print (f'time: 0, {res[0]}')\n",
    "\n",
    "start_time = time()\n",
    "total_tasks = 0\n",
    "for i in range(NR_STEPS):\n",
    "    if i < len(TASKS):\n",
    "        cluster.addTasks(TASKS[i], life_time = 1e6)\n",
    "    cluster.update()    \n",
    "    t = cluster.env.now\n",
    "    metrics = cluster.getMetrics()\n",
    "    #print (f'time: {t}, {metrics}')\n",
    "    res[t] = metrics\n",
    "\n",
    "df = dic2DF(res)\n",
    "plotClusterHistory(df)\n",
    "working_cost, total_cost = computeCost(df)\n",
    "print (f'WORKING_COST: {working_cost}, TOTAL COST: {total_cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Static Cluster Conclusions\n",
    "This cluster could not finish all the given tasks within the defined time frame.  All the tasks were sent relatively quickly, so in the beginning Deployment 1 was a bottleneck. In time, the most time and CPU consumming work was conducted by deployment 2. One can also notice, that Deployment 3 was now fully loaded - quite often it has only one, or even zero active tasks. \n",
    "\n",
    "In summary: Such a cluster works, but clearly it can be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Basic HPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the cluster is controled by a simple set of rules implemented in `HPABasic` class. By controlling a cluster I mean increasing or decreasing a number of pods for each deployment. `HPABasic` class controls the number of pods based on two simple rules:\n",
    "- if there are more than 5 tasks in the queue (not started), increase the number of pods for this deployment\n",
    "- if there are no activePods (the deployment is not working on any task), reduce the number of pods. *Note - the number of pods can never be less than 1.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPABasic:\n",
    "    def __init__(self):\n",
    "        self.deploymentMetrics = []\n",
    "        pass\n",
    "    \n",
    "    def processMetrics(self, metrics):\n",
    "        self.deploymentMetrics = []\n",
    "        metrics = metrics[2:]\n",
    "        for m in metrics:\n",
    "            self.deploymentMetrics.append(Metric(m))\n",
    "\n",
    "        update_deployments = [0] * len(self.deploymentMetrics)\n",
    "        for i, m in enumerate(self.deploymentMetrics):\n",
    "            if m.queueTasks > 5:\n",
    "                update_deployments[i] = 1\n",
    "            elif m.activePods == 0:\n",
    "                update_deployments[i] = -1\n",
    "\n",
    "        return update_deployments\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = createCluster()\n",
    "res = {}\n",
    "res[0] = cluster.getMetrics()\n",
    "#print (f'time: 0, {res[0]}')\n",
    "hpa = HPABasic()\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "total_tasks = 0\n",
    "for i in range(NR_STEPS):\n",
    "    if i < len(TASKS):\n",
    "        cluster.addTasks(TASKS[i], life_time = 1e6)\n",
    "    cluster.update()    \n",
    "    t = cluster.env.now\n",
    "    metrics = cluster.getMetrics()\n",
    "    #print (f'time: {t}, {metrics}')\n",
    "    res[t] = metrics\n",
    "    update_deployments = hpa.processMetrics(metrics)    \n",
    "    cluster.updateDeployments(update_deployments)\n",
    "    sleep(1e-3)\n",
    "\n",
    "df = dic2DF(res)\n",
    "plotClusterHistory(df)\n",
    "working_cost, total_cost = computeCost(df)\n",
    "print (f'WORKING_COST: {working_cost}, TOTAL COST: {total_cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3 conclusions\n",
    "The scaling process worked as expected, the cluster managed to solve all the tasks within a given time frame. In fact, it went really fast - it required around 50 miliseconds to solve everything.\n",
    "\n",
    "The largest bottleneck (in Deployment 2) was solved by significant increase in the number of pods for this deployment - in a peek, it went up from 4 to 17 deployments. \n",
    "\n",
    "The only problem with such an approach is the CPU usage, that is not restricted by any rules. This resulted with the maximum usage (in a peek) over 400 units, compared to 150 units in a peek for the previous experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 - CPU sensitive HPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the cluster is controled by a bit more advanced HPA, that pays attention not only to the number of tasks, but also to the total number of pods. The goal is to optimize the number of pods, and, simultaneously, keep the maximum number of pods within the certain limits (not more than 7 pods to keep it consistent with the first experiments). \n",
    "A set of rules implemented in `HPA1` class is based on two thresholds:\n",
    "- pod_warning (here: 3)\n",
    "- pod_max (here: 7)\n",
    "\n",
    "and looks as follows:\n",
    "- if the total number of pods exceeds pod_max, do not increase the number of pods\n",
    "- otherwise, if there are more than 5 tasks in the queue (for any deployment):\n",
    "    - if the total number of pods exceeds pod_warning, increase the number of pods only in the deployment with the largest number of the tasks in the queue\n",
    "    - otherwise increase the number of pods fo each deployment with more than 5 tasks in the queue    \n",
    "- if there are no activePods (the deployment is not working on any task), reduce the number of pods. *Note - the number of pods can never be less than 1.*\n",
    "\n",
    "\n",
    "**Note: 700 CPU units corresponds to 7 pods from the first experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPA1:\n",
    "    def __init__(self, pod_warning = 3, pod_max = 7):\n",
    "        self.pod_warning = pod_warning\n",
    "        self.pod_max = pod_max\n",
    "        self.deploymentMetrics = []\n",
    "        pass\n",
    "    \n",
    "    def processMetrics(self, metrics):\n",
    "        self.deploymentMetrics = []\n",
    "        metrics = metrics[2:]\n",
    "        for m in metrics:\n",
    "            self.deploymentMetrics.append(Metric(m))\n",
    "            \n",
    "\n",
    "        update_deployments = [0] * len(self.deploymentMetrics)\n",
    "        nr_pods = sum([m.pods for m in self.deploymentMetrics])\n",
    "        \n",
    "        to_increase = -1\n",
    "        queue_tasks_max = 0\n",
    "        \n",
    "        for i, m in enumerate(self.deploymentMetrics):\n",
    "            if m.queueTasks > 5:\n",
    "                if nr_pods < self.pod_warning:\n",
    "                    update_deployments[i] = 1\n",
    "                elif nr_pods < self.pod_max:\n",
    "                    if m.queueTasks > queue_tasks_max:\n",
    "                        queue_tasks_max = m.queueTasks\n",
    "                        to_increase = i\n",
    "            elif m.activePods == 0:\n",
    "                update_deployments[i] = -1\n",
    "\n",
    "        if to_increase >= 0:\n",
    "            update_deployments[to_increase] = 1\n",
    "                \n",
    "        return update_deployments\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpa = HPA1()\n",
    "cluster = createCluster()\n",
    "res = {}\n",
    "res[0] = cluster.getMetrics()\n",
    "#print (f'time: 0, {res[0]}')\n",
    "\n",
    "start_time = time()\n",
    "total_tasks = 0\n",
    "for i in range(NR_STEPS):\n",
    "    if i < len(TASKS):\n",
    "        cluster.addTasks(TASKS[i], life_time = 1e6)\n",
    "    cluster.update()    \n",
    "    t = cluster.env.now\n",
    "    metrics = cluster.getMetrics()\n",
    "    #print (f'time: {t}, {metrics}')\n",
    "    res[t] = metrics\n",
    "    update_deployments = hpa.processMetrics(metrics)    \n",
    "    cluster.updateDeployments(update_deployments)\n",
    "    sleep(1e-3)\n",
    "\n",
    "df = dic2DF(res)\n",
    "plotClusterHistory(df)\n",
    "working_cost, total_cost = computeCost(df)\n",
    "print (f'WORKING_COST: {working_cost}, TOTAL COST: {total_cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4 - conclusions\n",
    "In short - it worked. The cluster did not exceed the assumed CPU consumption, and managed to finish the tasks in time. I think it may be used even for a more complicated cluster. However, based on the `queueTasks` chart one can notice, that there is still a bottleneck in Deployment 2. Such bottleneck suggests that there is still a space for optimalization. This bottleneck can be solved by more advanced cluster controller, this is where we hope to employe Reinforecement Learning agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
